{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen \n",
    "\n",
    "[AutoGen](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/installation.html) is a programming framework for agentic.\n",
    "\n",
    "Install the dependencies library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU autogen-agentchat \"autogen-ext[openai]\" \"autogen-ext[ollama]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup LLM and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qwen2.5:7b'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from getpass import getpass\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API base URL and model with default values\n",
    "OPENAI_API_BASE = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o\")\n",
    "\n",
    "# Set up OpenAI API configuration\n",
    "# Try to get API key from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# If not found, ask user to input it\n",
    "if not OPENAI_API_KEY:\n",
    "    OPENAI_API_KEY = getpass(\"Enter your OpenAI API key:\")\n",
    "\n",
    "OPENAI_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! Here\\'s a short story for you:\\n\\n---\\n\\nIn the heart of a bustling city stood an old bookstore that had seen better days. Its shelves were lined with faded books, and the walls whispered tales of forgotten times. The owner, Mr. Elwood, was known for his vast knowledge and the unwavering belief in the magic of stories.\\n\\nOne rainy afternoon, a young girl named Lily wandered into the bookstore, her eyes wide with curiosity. She walked between the rows of books, feeling the cool leather bindings and the soft paper pages. Mr. Elwood noticed her and approached, asking if she was looking for something specific.\\n\\nLily shook her head but smiled, explaining that she often dreamed of a world beyond the ones in these books. \"Do you think,\" she asked hesitantly, \"that stories can really change things?\"\\n\\nMr. Elwood nodded warmly, his eyes gleaming with memories. He led her to a book he had recently acquired: \"The Chronicles of the Forgotten Realm.\" As they sat on creaky chairs, he began reading aloud.\\n\\nThe story transported them to a land filled with adventure and magic, where brave heroes faced challenges and overcame them with wisdom and courage. Lily was entranced, feeling like she too could be part of such a journey.\\n\\nWhen Mr. Elwood finished the chapter, they both realized it had started to rain outside. Lily stood up, her face alight with newfound determination. \"I know what I need to do,\" she said excitedly.\\n\\nThe next morning, with Mr. Elwood\\'s help, Lily wrote a story of her own—a tale filled with imagination and hope. She shared her story with the world through a small blog she started, inspiring many others who felt lost or alone.\\n\\nYears passed, and the old bookstore became a beacon of creativity, hosting writing workshops and book readings. Mr. Elwood continued to share stories that changed lives, much like the ones he had read to Lily on that rainy day.\\n\\nLily’s story was just beginning, but she knew it would be full of adventure and magic—thanks to an old man who believed in the power of tales.\\n\\n---\\n\\nI hope you enjoyed this little tale!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "from autogen_core.models import UserMessage\n",
    "\n",
    "# client = OpenAIChatCompletionClient(\n",
    "#     model=OPENAI_MODEL,\n",
    "#     api_key=OPENAI_API_KEY,\n",
    "#     base_url=OPENAI_API_BASE,\n",
    "# )\n",
    "\n",
    "client = OllamaChatCompletionClient(\n",
    "    model=OPENAI_MODEL\n",
    ")\n",
    "\n",
    "result = await client.create([UserMessage(content=\"tell me a short story\",source=\"user\")])\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=client,\n",
    "    tools=[],\n",
    "    system_message=\"Use tools to slove tasks.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "source='assistant' models_usage=RequestUsage(prompt_tokens=38, completion_tokens=139) metadata={} content='To solve the expression \\\\(1.77 + 3.23 \\\\times 2.72\\\\), follow these steps:\\n\\n1. First, perform the multiplication:\\n   \\\\[\\n   3.23 \\\\times 2.72 = 8.7936\\n   \\\\]\\n\\n2. Then add the result to 1.77:\\n   \\\\[\\n   1.77 + 8.7936 = 10.5636\\n   \\\\]\\n\\nSo, \\\\(1.77 + 3.23 \\\\times 2.72 = 10.5636\\\\).' type='TextMessage'\n"
     ]
    }
   ],
   "source": [
    "response = await agent.on_messages(\n",
    "    [TextMessage(content=\"What is 1.77+3.23*2.72?\", source=\"user\")],\n",
    "    cancellation_token=CancellationToken(),\n",
    ")\n",
    "# inner_messages are agent's \"thought process\" messages\n",
    "print(response.inner_messages)\n",
    "# agent_message is the final message from the assistant\n",
    "print(response.chat_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- assistant ----------\n",
      "Sure! Here's a short story for you:\n",
      "\n",
      "---\n",
      "\n",
      "In the small town of Willowbrook, there lived an old clockmaker named Eli. His shop was tucked away on a quiet street, and it was said that his clocks never stopped ticking—though they did stop at exactly midnight every night.\n",
      "\n",
      "One stormy evening, a young girl named Lily knocked on Eli's door, seeking shelter from the rain. As she stood in the warmth of his workshop, Eli noticed her curious gaze fixed on an old, dusty clock. \"I can fix it,\" he offered, pointing to the clock with a wink.\n",
      "\n",
      "Lily was skeptical but agreed to let Eli try. The next morning, as the sun rose, Lily woke up to find that not only did all the clocks in Willowbrook start working again at midnight, but her own heart seemed lighter. She realized that sometimes, what seems broken can be mended by a little kindness and unexpected magic.\n",
      "\n",
      "---\n",
      "\n",
      "I hope you enjoyed this short story!\n",
      "[Prompt tokens: 191, Completion tokens: 199]\n",
      "---------- Summary ----------\n",
      "Number of inner messages: 0\n",
      "Total prompt tokens: 191\n",
      "Total completion tokens: 199\n",
      "Duration: 3.51 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(chat_message=TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=191, completion_tokens=199), metadata={}, content='Sure! Here\\'s a short story for you:\\n\\n---\\n\\nIn the small town of Willowbrook, there lived an old clockmaker named Eli. His shop was tucked away on a quiet street, and it was said that his clocks never stopped ticking—though they did stop at exactly midnight every night.\\n\\nOne stormy evening, a young girl named Lily knocked on Eli\\'s door, seeking shelter from the rain. As she stood in the warmth of his workshop, Eli noticed her curious gaze fixed on an old, dusty clock. \"I can fix it,\" he offered, pointing to the clock with a wink.\\n\\nLily was skeptical but agreed to let Eli try. The next morning, as the sun rose, Lily woke up to find that not only did all the clocks in Willowbrook start working again at midnight, but her own heart seemed lighter. She realized that sometimes, what seems broken can be mended by a little kindness and unexpected magic.\\n\\n---\\n\\nI hope you enjoyed this short story!', type='TextMessage'), inner_messages=[])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(\n",
    "    agent.on_messages_stream(\n",
    "        [TextMessage(content=\"tell me a short story\", source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    ),\n",
    "    output_stats=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source='assistant' models_usage=None metadata={} content='Once' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' upon' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' a' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' time' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' in' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' a' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' small' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' village' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' nestled' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' between' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' rolling' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' hills' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' and' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' a' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' sparkling' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' river' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' there' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' lived' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' a' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' young' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' girl' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' named' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' Lily' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' Lily' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' was' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' known' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' throughout' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' village' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' for' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' her' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' kind' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' heart' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' and' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' curious' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' spirit' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' She' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' spent' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' most' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' of' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' her' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' days' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' exploring' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' forest' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' that' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' bordered' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' village' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' always' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' eager' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' to' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' uncover' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' its' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' secrets' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.\\n\\n' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='One' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' sunny' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' morning' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' as' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' she' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' was' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' wandering' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' through' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' dense' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' under' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='brush' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' Lily' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' stumbled' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' upon' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' an' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' old' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' gn' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='ar' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='led' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' tree' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' with' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' a' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' small' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' door' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' hidden' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' behind' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' moss' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' and' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' iv' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='y' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' Cur' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='ious' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' she' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' pushed' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' door' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' open' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' and' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' stepped' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' inside' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' finding' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' herself' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' in' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' a' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' tiny' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' room' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' filled' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' with' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' most' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' beautiful' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' lights' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' that' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' seemed' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' to' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' dance' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' and' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' tw' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='inkle' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' on' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' their' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' own' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.\\n\\n' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='The' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' room' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' was' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' home' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' to' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' a' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' family' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' of' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' fair' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='ies' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' who' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' had' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' been' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' watching' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' Lily' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' from' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' afar' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' capt' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='ivated' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' by' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' her' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' goodness' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' The' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' fair' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='ies' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' invited' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' her' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' to' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' stay' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' for' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' tea' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' and' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' share' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' stories' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' Over' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' sweet' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' treats' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' and' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' laughter' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' Lily' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' learned' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' about' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' magical' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' creatures' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' who' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' lived' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' in' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' harmony' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' with' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' nature' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' invisible' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' to' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' most' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' but' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' always' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' there' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' keeping' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' watch' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.\\n\\n' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='As' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' sun' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' began' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' to' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' set' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' Lily' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' realized' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' it' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' was' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' time' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' to' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' return' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' home' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' Before' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' she' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' left' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' fairy' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' family' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' gifted' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' her' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' a' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' small' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' shimmer' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='ing' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' lo' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='cket' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' that' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' would' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' light' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' up' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' whenever' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' she' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' needed' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' guidance' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' or' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' wished' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' to' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' see' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' them' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' again' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' Lily' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' hugged' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' each' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' of' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' fair' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='ies' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' tightly' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' and' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' promised' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' to' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' keep' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' their' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' world' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' safe' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' as' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' she' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' ventured' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' back' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' through' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' door' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.\\n\\n' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='On' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' her' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' way' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' out' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' she' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' noticed' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' something' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' shiny' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' on' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' a' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' nearby' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' leaf' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='—it' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' was' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' one' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' of' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' fair' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='ies' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='’' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' lost' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' spark' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='les' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' Lily' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' picked' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' it' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' up' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' and' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' placed' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' it' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' back' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' in' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' its' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' rightful' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' home' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' ensuring' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' fairy' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' family' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=\"'s\" type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' happiness' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' As' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' she' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' emerged' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' from' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' tree' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' lo' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='cket' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' began' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' to' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' glow' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' faint' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='ly' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' a' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' reminder' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' of' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' magical' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' world' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' that' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' lay' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' just' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' beyond' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' her' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' ordinary' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' life' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.\\n\\n' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='From' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' that' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' day' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' on' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' whenever' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' Lily' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' needed' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' strength' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' or' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' inspiration' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' she' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' would' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' look' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' at' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' glowing' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' lo' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='cket' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' and' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' remember' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' her' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' adventures' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' among' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' the' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' fair' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='ies' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' And' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' though' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' no' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' one' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' else' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' ever' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' saw' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' them' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' she' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' felt' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' their' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' presence' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' guiding' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' her' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=',' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' making' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' her' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' journey' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' through' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' life' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' a' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' little' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' bit' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' more' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content=' enchant' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='ing' type='ModelClientStreamingChunkEvent'\n",
      "source='assistant' models_usage=None metadata={} content='.' type='ModelClientStreamingChunkEvent'\n",
      "Response(chat_message=TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=25, completion_tokens=400), metadata={}, content=\"Once upon a time, in a small village nestled between rolling hills and a sparkling river, there lived a young girl named Lily. Lily was known throughout the village for her kind heart and curious spirit. She spent most of her days exploring the forest that bordered the village, always eager to uncover its secrets.\\n\\nOne sunny morning, as she was wandering through the dense underbrush, Lily stumbled upon an old, gnarled tree with a small door hidden behind moss and ivy. Curious, she pushed the door open and stepped inside, finding herself in a tiny room filled with the most beautiful lights that seemed to dance and twinkle on their own.\\n\\nThe room was home to a family of fairies who had been watching Lily from afar, captivated by her goodness. The fairies invited her to stay for tea and share stories. Over sweet treats and laughter, Lily learned about the magical creatures who lived in harmony with nature, invisible to most but always there, keeping watch.\\n\\nAs the sun began to set, Lily realized it was time to return home. Before she left, the fairy family gifted her a small, shimmering locket that would light up whenever she needed guidance or wished to see them again. Lily hugged each of the fairies tightly and promised to keep their world safe as she ventured back through the door.\\n\\nOn her way out, she noticed something shiny on a nearby leaf—it was one of the fairies’ lost sparkles. Lily picked it up and placed it back in its rightful home, ensuring the fairy family's happiness. As she emerged from the tree, the locket began to glow faintly, a reminder of the magical world that lay just beyond her ordinary life.\\n\\nFrom that day on, whenever Lily needed strength or inspiration, she would look at the glowing locket and remember her adventures among the fairies. And though no one else ever saw them, she felt their presence guiding her, making her journey through life a little bit more enchanting.\", type='TextMessage'), inner_messages=[])\n"
     ]
    }
   ],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=client,\n",
    "    tools=[],\n",
    "    system_message=\"Use tools to slove tasks.\",\n",
    "    model_client_stream=True, # Enable streaming tokens\n",
    ")\n",
    "\n",
    "async for message in agent.on_messages_stream(\n",
    "    [TextMessage(content=\"tell me a short story\", source=\"user\")],\n",
    "    cancellation_token=CancellationToken(),\n",
    "):\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similary, `run_stream()` will also yiled the same streming chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here’s a short story for you:\n",
      "\n",
      "---\n",
      "\n",
      "In a small village nestled among rolling hills and winding rivers, there lived an old watchmaker named Harold. Known for his precise craftsmanship and kind heart, Harold spent most of his days mending clocks and watches, ensuring they kept perfect time.\n",
      "\n",
      "One rainy afternoon, a young boy named Timmy wandered into Harold's shop. Timmy was curious about the intricate gears and cogs that filled the room, each ticking rhythm creating a soothing melody in the background.\n",
      "\n",
      "\"Hello there,\" Harold said with a warm smile. \"What brings you to my shop on such a dreary day?\"\n",
      "\n",
      "Timmy held up his wristwatch, which had stopped working during the rainstorm. \"My watch isn't working anymore. Can you fix it?\" he asked hopefully.\n",
      "\n",
      "Harold took the watch and examined it carefully. After some gentle adjustments, the watch sprang back to life, its hands moving smoothly again.\n",
      "\n",
      "\"Thank you so much!\" Timmy exclaimed, beaming with delight.\n",
      "\n",
      "Harold handed him the watch and said, \"It’s no trouble at all. Sometimes, a little care can bring things back to life.\"\n",
      "\n",
      "As Timmy left the shop, Harold noticed a small, worn pocket watch on the counter. It was old but well-made, with delicate engravings that seemed familiar. He picked it up and examined it closely.\n",
      "\n",
      "The engraving read: \"For Lily, with love.\" A name that tugged at his memory. Harold remembered Lily, a young girl who used to visit him often when she was younger. She had left the village years ago, leaving behind only this watch as a memento of their time together.\n",
      "\n",
      "Deciding to investigate further, Harold cleaned and polished the watch until its beauty shone through. Inside, he found a tiny note that read: \"Meet me at the old oak tree tomorrow at sunset.\"\n",
      "\n",
      "Curious, Harold made plans for the next day. As the sun began to set, he walked to the old oak tree in the village square. There, he found Lily, who had returned unexpectedly.\n",
      "\n",
      "Lily smiled when she saw him. \"I knew you’d come,\" she said softly.\n",
      "\n",
      "Harold handed her the watch. \"It’s yours again,\" he said, his heart warming at seeing her smile.\n",
      "\n",
      "They spent the evening talking about old times and catching up on each other's lives. Lily revealed that she had been searching for Harold for years, hoping to return the watch and reconnect with him.\n",
      "\n",
      "As night fell, they sat by the tree, watching the stars appear one by one. Harold realized that sometimes, it takes a little care and patience to bring back not just a watch, but lost connections and memories.\n",
      "\n",
      "From that day on, Harold and Lily rekindled their friendship, meeting regularly at the old oak tree to share stories and laughter. And every time they saw each other, Harold would smile, knowing that he had helped mend more than just a broken watch.\n",
      "\n",
      "---\n",
      "\n",
      "And so, in the small village, the old oak tree became a symbol of hope and connection, reminding everyone that sometimes, all it takes is a little care to bring back what was lost."
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.messages import ModelClientStreamingChunkEvent\n",
    "\n",
    "async for message in agent.run_stream(task=\"tell me a short story\"):\n",
    "    if isinstance(message, TextMessage):\n",
    "        # print(message.content)\n",
    "        pass\n",
    "    elif isinstance(message, ModelClientStreamingChunkEvent):\n",
    "        print(message.content, end=\"\")\n",
    "    else:\n",
    "        # Handle other message types if needed\n",
    "        # For example, if you have a custom message type\n",
    "        # you can process it accordingly\n",
    "        # print(\"Other message type:\", message)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "### Function tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tool(x: float, y: float) -> float:\n",
    "    \"\"\"\n",
    "    Add X and Y to get the exact result.\n",
    "\n",
    "    Args:\n",
    "        x (float): First number.\n",
    "        y (float): Second number.\n",
    "\n",
    "    Returns:\n",
    "        float: The sum of X and Y.\n",
    "    \"\"\"\n",
    "    return x + y\n",
    "\n",
    "def subtract_tool(x: float, y: float) -> str:\n",
    "    \"\"\"\n",
    "    Subtract Y from X to get the exact result.\n",
    "\n",
    "    Args:\n",
    "        x (float): First number.\n",
    "        y (float): Second number.\n",
    "\n",
    "    Returns:\n",
    "        str: The difference of X and Y.\n",
    "    \"\"\"\n",
    "    return str(x - y)\n",
    "\n",
    "def multiply_tool(x: float, y: float) -> str:\n",
    "    \"\"\"\n",
    "    Multiply X and Y to get the exact result.\n",
    "\n",
    "    Args:\n",
    "        x (float): First number.\n",
    "        y (float): Second number.\n",
    "\n",
    "    Returns:\n",
    "        str: The product of X and Y.\n",
    "    \"\"\"\n",
    "    return str(x * y)\n",
    "\n",
    "def divide_tool(x: float, y: float) -> str:\n",
    "    \"\"\"\n",
    "    Divide X by Y to get the exact result.\n",
    "\n",
    "    Args:\n",
    "        x (float): First number.\n",
    "        y (float): Second number.\n",
    "\n",
    "    Returns:\n",
    "        str: The quotient of X and Y.\n",
    "    \"\"\"\n",
    "    return str(x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an Agent with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- assistant ----------\n",
      "[FunctionCall(id='3', arguments='{\"x\": 3.23, \"y\": 2.72}', name='multiply_tool')]\n",
      "[Prompt tokens: 547, Completion tokens: 100]\n",
      "---------- assistant ----------\n",
      "[FunctionExecutionResult(content='8.7856', name='multiply_tool', call_id='3', is_error=False)]\n",
      "---------- assistant ----------\n",
      "8.7856\n",
      "---------- Summary ----------\n",
      "Number of inner messages: 2\n",
      "Total prompt tokens: 547\n",
      "Total completion tokens: 100\n",
      "Duration: 4.43 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(chat_message=ToolCallSummaryMessage(source='assistant', models_usage=None, metadata={}, content='8.7856', type='ToolCallSummaryMessage'), inner_messages=[ToolCallRequestEvent(source='assistant', models_usage=RequestUsage(prompt_tokens=547, completion_tokens=100), metadata={}, content=[FunctionCall(id='3', arguments='{\"x\": 3.23, \"y\": 2.72}', name='multiply_tool')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='assistant', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='8.7856', name='multiply_tool', call_id='3', is_error=False)], type='ToolCallExecutionEvent')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=client,\n",
    "    tools=[add_tool, subtract_tool, multiply_tool, divide_tool],\n",
    "    system_message=\"Use tools to slove tasks.\"\n",
    ")\n",
    "\n",
    "await Console(\n",
    "    agent.on_messages_stream(\n",
    "        [TextMessage(content=\"What is 1.77+3.23*2.72?\", source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    ),\n",
    "    output_stats=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational Agent\n",
    "\n",
    "`AssistantAgent` can use `model_context` to pass in a `ChatCompletionContext` object. It allows the agent to use different model contexts. By default, `AssistantAgent` uses the `UnboundedChatCompletionContext` which sends the full conversation history to the model. To limit the context to the last `n` messages, you can use the `BufferedChatCompletionContext`. To limit the context by token count, you can use the `TokenLimitedChatCompletionContext`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- assistant ----------\n",
      "[FunctionCall(id='20', arguments='{\"x\": 1.3, \"y\": 2}', name='multiply_tool')]\n",
      "[Prompt tokens: 541, Completion tokens: 28]\n",
      "---------- assistant ----------\n",
      "[FunctionExecutionResult(content='2.6', name='multiply_tool', call_id='20', is_error=False)]\n",
      "---------- assistant ----------\n",
      "2.6\n",
      "---------- Summary ----------\n",
      "Number of inner messages: 2\n",
      "Total prompt tokens: 541\n",
      "Total completion tokens: 28\n",
      "Duration: 0.66 seconds\n",
      "---------- assistant ----------\n",
      "To help you calculate the value of `b`, I need to know the value of `a`. Could you please provide me with the value of `a`?\n",
      "[Prompt tokens: 540, Completion tokens: 34]\n",
      "---------- Summary ----------\n",
      "Number of inner messages: 0\n",
      "Total prompt tokens: 540\n",
      "Total completion tokens: 34\n",
      "Duration: 0.64 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(chat_message=TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=540, completion_tokens=34), metadata={}, content='To help you calculate the value of `b`, I need to know the value of `a`. Could you please provide me with the value of `a`?', type='TextMessage'), inner_messages=[])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_core.model_context import BufferedChatCompletionContext\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=client,\n",
    "    tools=[add_tool, subtract_tool, multiply_tool, divide_tool],\n",
    "    system_message=\"Use tools to slove tasks.\",\n",
    "    model_context=BufferedChatCompletionContext(buffer_size=2),\n",
    ")\n",
    "\n",
    "await Console(\n",
    "    agent.on_messages_stream(\n",
    "        [TextMessage(content=\"a=1.3*2, tell me a=?\", source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    ),\n",
    "    output_stats=True,\n",
    ")\n",
    "await Console(\n",
    "    agent.on_messages_stream(\n",
    "        [TextMessage(content=\"b=1.3*a, What is b?\", source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    ),\n",
    "    output_stats=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `a=1.3*2` is required to call Function Call, in essence it has a dialog that generates Function Call and then calls Function Call, so when the buffer size is 2, it only has 2.6 and the notation of executing function exectution, and it doesn't know what a is anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- assistant ----------\n",
      "[FunctionCall(id='23', arguments='{\"x\": 1.3, \"y\": 2}', name='multiply_tool')]\n",
      "[Prompt tokens: 541, Completion tokens: 28]\n",
      "---------- assistant ----------\n",
      "[FunctionExecutionResult(content='2.6', name='multiply_tool', call_id='23', is_error=False)]\n",
      "---------- assistant ----------\n",
      "2.6\n",
      "---------- Summary ----------\n",
      "Number of inner messages: 2\n",
      "Total prompt tokens: 541\n",
      "Total completion tokens: 28\n",
      "Duration: 2.03 seconds\n",
      "---------- assistant ----------\n",
      "<tool_call>\n",
      "{\"name\": \"multiply_tool\", \"arguments\": {\"x\": 1.3, \"y\": a}}\n",
      "</tool_call>\n",
      "[Prompt tokens: 586, Completion tokens: 27]\n",
      "---------- Summary ----------\n",
      "Number of inner messages: 0\n",
      "Total prompt tokens: 586\n",
      "Total completion tokens: 27\n",
      "Duration: 0.58 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(chat_message=TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=586, completion_tokens=27), metadata={}, content='<tool_call>\\n{\"name\": \"multiply_tool\", \"arguments\": {\"x\": 1.3, \"y\": a}}\\n</tool_call>', type='TextMessage'), inner_messages=[])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_core.model_context import BufferedChatCompletionContext\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=client,\n",
    "    tools=[add_tool, subtract_tool, multiply_tool, divide_tool],\n",
    "    system_message=\"Use tools to slove tasks.\",\n",
    "    model_context=BufferedChatCompletionContext(buffer_size=3),\n",
    ")\n",
    "\n",
    "await Console(\n",
    "    agent.on_messages_stream(\n",
    "        [TextMessage(content=\"a=1.3*2, what is a?\", source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    ),\n",
    "    output_stats=True,\n",
    ")\n",
    "await Console(\n",
    "    agent.on_messages_stream(\n",
    "        [TextMessage(content=\"b=1.3*a, What is b?\", source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    ),\n",
    "    output_stats=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
